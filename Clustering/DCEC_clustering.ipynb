{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Reshape\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1878, 25, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load('../npy_files/features_All25.npy')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 4 \n",
    "class Autoencoder_Base(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder_Base, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      Flatten(),\n",
    "      Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      Dense(125, activation='sigmoid'),\n",
    "      Reshape((25, 5))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder_Base(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "autoencoder.build(input_shape=(1,25,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (1, 125)                  0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (1, 4)                    504       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504\n",
      "Trainable params: 504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 41.6211\n",
      "Epoch 2/5\n",
      "59/59 [==============================] - 0s 965us/step - loss: 41.4965\n",
      "Epoch 3/5\n",
      "59/59 [==============================] - 0s 969us/step - loss: 41.4430\n",
      "Epoch 4/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.4271\n",
      "Epoch 5/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.4222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd8ce4e3a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x, x,\n",
    "                epochs=5,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_Dense(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder_Dense, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = Sequential([\n",
    "      Flatten(),\n",
    "      Dense(32, activation=\"relu\",name='dense1'),\n",
    "      Dense(16, activation=\"relu\",name='dense2'),\n",
    "      Dense(latent_dim, activation=\"relu\",name='dense3')])\n",
    "\n",
    "    self.decoder = Sequential([\n",
    "      Dense(16, activation=\"relu\",name='dedense1'),\n",
    "      Dense(32, activation=\"relu\",name='dedense2'),\n",
    "      Dense(125, activation=\"sigmoid\",name='dedense3'),\n",
    "      Reshape((25, 5) , name='reshape1')\n",
    "      ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder_Dense(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "autoencoder.build(input_shape=(1,25,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                4032      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 16)                528       \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 8)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,696\n",
      "Trainable params: 4,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dedense1 (Dense)            (None, 16)                144       \n",
      "                                                                 \n",
      " dedense2 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dedense3 (Dense)            (None, 125)               4125      \n",
      "                                                                 \n",
      " reshape1 (Reshape)          (None, 25, 5)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,813\n",
      "Trainable params: 4,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.2765\n",
      "Epoch 2/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.2767\n",
      "Epoch 3/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.2758\n",
      "Epoch 4/5\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 41.2755\n",
      "Epoch 5/5\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 41.2755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd8bc8af40>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x, x,\n",
    "                epochs=5,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAE_mod(input_shape=(5,5,5), filters=[16, 32, 64, 3]):\n",
    "    model = Sequential()\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    model.add(Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2'))\n",
    "\n",
    "    model.add(Conv2D(filters[2], 2, strides=1, padding=pad3, activation='relu', name='conv3'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=filters[3], name='embedding'))\n",
    "    model.add(Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu'))\n",
    "\n",
    "    model.add(Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2])))\n",
    "    model.add(Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3'))\n",
    "\n",
    "    model.add(Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2'))\n",
    "\n",
    "    model.add(Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1'))\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 3, 3, 16)          2016      \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 2, 2, 32)          12832     \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 1, 1, 64)          8256      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " embedding (Dense)           (None, 3)                 195       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 0)                 0         \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 0, 0, 64)          0         \n",
      "                                                                 \n",
      " deconv3 (Conv2DTranspose)   (None, 1, 1, 32)          18464     \n",
      "                                                                 \n",
      " deconv2 (Conv2DTranspose)   (None, 2, 2, 16)          12816     \n",
      "                                                                 \n",
      " deconv1 (Conv2DTranspose)   (None, 4, 4, 5)           2005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,584\n",
      "Trainable params: 56,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cae = CAE_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_24\" is incompatible with the layer: expected shape=(None, 5, 5, 5), found shape=(None, 25, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\DL-WORKSHOP\\Clustering\\DCEC_clustering.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/TAU/DL-Workshop/Git%20Folder/DL-WORKSHOP/Clustering/DCEC_clustering.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cae\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/TAU/DL-Workshop/Git%20Folder/DL-WORKSHOP/Clustering/DCEC_clustering.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cae\u001b[39m.\u001b[39;49mfit(x, x, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_24\" is incompatible with the layer: expected shape=(None, 5, 5, 5), found shape=(None, 25, 5)\n"
     ]
    }
   ],
   "source": [
    "cae.compile(optimizer='adam', loss='mse')\n",
    "cae.fit(x, x, batch_size=256, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(25,5)))\n",
    "model.add(RepeatVector(25))\n",
    "model.add(LSTM(5, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(5)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, x, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfa.rnn.PeepholeLSTMCell(4 , activation=tf.nn.tanh,input_shape=(25,5),name=\"encoder\")\n",
    "rnn_enc = tf.keras.layers.RNN(encoder, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder = tfa.rnn.PeepholeLSTMCell(4 , activation=tf.nn.tanh,name=\"decoder\")\n",
    "rnn_dec = tf.keras.layers.RNN(decoder, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "model = Sequential()\n",
    "model.add(rnn_enc)\n",
    "model.add(RepeatVector(25))\n",
    "model.add(rnn_dec)\n",
    "model.add(TimeDistributed(Dense(5)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\sequential.py\", line 318, in _build_graph_network_for_inferred_shape\n        raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n\n    ValueError: Exception encountered when calling layer \"sequential_33\" (type Sequential).\n    \n    All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 25, 5), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\DL-WORKSHOP\\Clustering\\DCEC_clustering.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/TAU/DL-Workshop/Git%20Folder/DL-WORKSHOP/Clustering/DCEC_clustering.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, x, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Projects\\TAU\\DL-Workshop\\Git Folder\\Env\\dl_work_mod\\lib\\site-packages\\keras\\engine\\sequential.py\", line 318, in _build_graph_network_for_inferred_shape\n        raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n\n    ValueError: Exception encountered when calling layer \"sequential_33\" (type Sequential).\n    \n    All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 25, 5), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(x, x, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1878, 25, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,:,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl_work_mod': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c034c402205727166c9c9dd79643745cea02dc6588a665f44be427a01cecf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
