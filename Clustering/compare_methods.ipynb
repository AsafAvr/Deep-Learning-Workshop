{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(False)\n",
    "import plotting_funcs as pf\n",
    "import config\n",
    "import prepare_data_for_clustering_utils as prep\n",
    "\n",
    "#from VaDER.vader import VADER\n",
    "#save_path = os.path.join('test_vader', 'vader.ckpt')\n",
    "#np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = prep.from_results_folder_PATH_to_arrays(features=['centroids','morphologies','embeddings'],ts_len=32,cut_longer_ts=True,save=True,name_ext=\"_WithEmbs32\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29808 29808\n"
     ]
    }
   ],
   "source": [
    "X = np.load('../npy_files/features_All16.npy')\n",
    "y = np.load('../npy_files/labels_All16.npy')\n",
    "types = np.load('../npy_files/celltypes_All16.npy')\n",
    "y_letter = np.array([well[:1] for well in y])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labs = le.fit_transform(y)\n",
    "labs_by_letter = le.fit_transform(y_letter)\n",
    "print(len(X),len(y))\n",
    "X_train, y_train = X, labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YFP+CFP', 'YFP+CFP', 'YFP+CFP', ..., 'control', 'control',\n",
       "       'control'], dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    15366\n",
       "G     7167\n",
       "F     5036\n",
       "E     2239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_letter).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D2    6240\n",
       "D4    3878\n",
       "G4    3234\n",
       "D3    3231\n",
       "F4    3095\n",
       "D7    2017\n",
       "G2    1582\n",
       "F3    1574\n",
       "E6    1387\n",
       "G3    1028\n",
       "E7     852\n",
       "G5     821\n",
       "G6     502\n",
       "F2     367\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train = None\n",
    "vader = VADER(X_train=X_train, W_train=W_train, save_path=save_path, n_hidden=[60,32,4], k=3,\n",
    "              learning_rate=1e-3, output_activation=None, recurrent=True, cell_type=\"GRU\", batch_size=64)\n",
    "# pre-train without latent loss\n",
    "start = time.time()\n",
    "vader.pre_fit(n_epoch=64, verbose=True)\n",
    "# train with latent loss\n",
    "vader.fit(n_epoch=64, verbose=True)\n",
    "end = time.time()\n",
    "print(\"Elapsed: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the clusters\n",
    "c = vader.cluster(X_train)\n",
    "# get the re-constructions\n",
    "p = vader.predict(X_train)\n",
    "# compute the loss given the network\n",
    "l = vader.get_loss(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(c).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = vader.map_to_latent(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex, hex_dict = pf.plot_clustering(latent,labs_by_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C0 = np.array([x for x,clust in zip(X_train,c) if clust == 0])\n",
    "X_C1 = np.array([x for x,clust in zip(X_train,c) if clust == 1])\n",
    "X_C2 = np.array([x for x,clust in zip(X_train,c) if clust == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 3\n",
    "representatives_C0 = X_C0[np.random.choice(X_C0.shape[0], n_reps, replace=False)]\n",
    "representatives_C1 = X_C1[np.random.choice(X_C1.shape[0], n_reps, replace=False)]\n",
    "representatives_C2 = X_C2[np.random.choice(X_C2.shape[0], n_reps, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_representatives([representatives_C0,representatives_C1,representatives_C2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specific well/gene group clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_G4 = np.array([x for x,well in zip(X,y) if well == \"G4\"])\n",
    "specific_c = vader.cluster(X_G4)\n",
    "specific_latent = vader.map_to_latent(X_G4)\n",
    "print(pd.Series(specific_c).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_F4 = np.array([x for x,well in zip(X,y) if well == \"E6\"])\n",
    "specific_c2 = vader.cluster(X_F4)\n",
    "specific_latent2 = vader.map_to_latent(X_F4)\n",
    "print(pd.Series(specific_c2).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_dual_clustering(specific_latent,specific_c,specific_latent2,specific_c2,hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = VADER(X_train=X_train, W_train=W_train, save_path=save_path, n_hidden=[64,4], k=3,\n",
    "              learning_rate=1e-3, output_activation=None, recurrent=True, cell_type=\"Transformer\", batch_size=64,\n",
    "              cell_params={'d_model': 4, 'num_layers': 1, 'num_heads': 1, 'dff': 16, 'rate': 0.0})\n",
    "# pre-train without latent loss\n",
    "start = time.time()\n",
    "vader.pre_fit(n_epoch=50, verbose=True)\n",
    "# train with latent loss\n",
    "vader.fit(n_epoch=50, verbose=True)\n",
    "end = time.time()\n",
    "print(\"Elapsed: \", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl_work_mod': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c034c402205727166c9c9dd79643745cea02dc6588a665f44be427a01cecf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
