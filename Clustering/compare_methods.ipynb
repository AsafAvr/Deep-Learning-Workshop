{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(False)\n",
    "from plotting_funcs import *\n",
    "\n",
    "#from VaDER.vader import VADER\n",
    "#save_path = os.path.join('test_vader', 'vader.ckpt')\n",
    "#np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../DL-WORKSHOP/npy_files/features_All12.npy')\n",
    "y = np.load('../DL-WORKSHOP/npy_files/labels_All12.npy')\n",
    "y_letter = np.array([well[:1] for well in y])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labs = le.fit_transform(y)\n",
    "labs_by_letter = le.fit_transform(y_letter)\n",
    "print(len(X),len(y))\n",
    "X_train, y_train = X, labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_letter).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize (better for fitting)\n",
    "for i in np.arange(X_train.shape[2]):\n",
    "    X_train[:,:,i] = (X_train[:,:,i] - np.mean(X_train[:,:,i])) / np.std(X_train[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train = None\n",
    "vader = VADER(X_train=X_train, W_train=W_train, save_path=save_path, n_hidden=[60,32,4], k=3,\n",
    "              learning_rate=1e-3, output_activation=None, recurrent=True, cell_type=\"GRU\", batch_size=64)\n",
    "# pre-train without latent loss\n",
    "start = time.time()\n",
    "vader.pre_fit(n_epoch=64, verbose=True)\n",
    "# train with latent loss\n",
    "vader.fit(n_epoch=64, verbose=True)\n",
    "end = time.time()\n",
    "print(\"Elapsed: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the clusters\n",
    "c = vader.cluster(X_train)\n",
    "# get the re-constructions\n",
    "p = vader.predict(X_train)\n",
    "# compute the loss given the network\n",
    "l = vader.get_loss(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(c).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = vader.map_to_latent(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex, hex_dict = plot_clustering(latent,labs_by_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specific well/gene group clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_G4 = np.array([x for x,well in zip(X,y) if well == \"G4\"])\n",
    "specific_c = vader.cluster(X_G4)\n",
    "specific_latent = vader.map_to_latent(X_G4)\n",
    "print(pd.Series(specific_c).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_F4 = np.array([x for x,well in zip(X,y) if well == \"E6\"])\n",
    "specific_c2 = vader.cluster(X_F4)\n",
    "specific_latent2 = vader.map_to_latent(X_F4)\n",
    "print(pd.Series(specific_c2).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_clustering(specific_latent,specific_c,specific_latent2,specific_c2,hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = VADER(X_train=X_train, W_train=W_train, save_path=save_path, n_hidden=[64,4], k=3,\n",
    "              learning_rate=1e-3, output_activation=None, recurrent=True, cell_type=\"Transformer\", batch_size=64,\n",
    "              cell_params={'d_model': 4, 'num_layers': 1, 'num_heads': 1, 'dff': 16, 'rate': 0.0})\n",
    "# pre-train without latent loss\n",
    "start = time.time()\n",
    "vader.pre_fit(n_epoch=50, verbose=True)\n",
    "# train with latent loss\n",
    "vader.fit(n_epoch=50, verbose=True)\n",
    "end = time.time()\n",
    "print(\"Elapsed: \", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
