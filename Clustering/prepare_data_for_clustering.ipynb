{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "PATH = '../Results_All'\n",
    "EXT = \"*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from datasets import load_mnist, load_usps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final pipeline for all features in all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "def using_clump(a):\n",
    "    return [a[s] for s in np.ma.clump_unmasked(np.ma.masked_where(a.astype(str)==str(np.nan),a))]\n",
    "def centroids_zero_center(tracks_arr):\n",
    "    for centroids_arr in tracks_arr:\n",
    "        centroids_arr -= centroids_arr[0]\n",
    "    return tracks_arr\n",
    "numeric_const_pattern = '[-+]? (?: (?: \\d* \\. \\d+ ) | (?: \\d+ \\.? ) )(?: [Ee] [+-]? \\d+ ) ?'\n",
    "rx = re.compile(numeric_const_pattern, re.VERBOSE)\n",
    "def str_array_to_float(arr_of_arr_of_str):\n",
    "    final_mat = []\n",
    "    for arr_of_arr in arr_of_arr_of_str:\n",
    "        float_ts = []\n",
    "        for str in arr_of_arr:\n",
    "            float_arr = [float(i) for i in rx.findall(str)]\n",
    "            if(len(float_arr)>=2):\n",
    "                float_ts.append(float_arr)\n",
    "        if(len(float_ts)>=1):\n",
    "            final_mat.append(float_ts)\n",
    "    return np.array(final_mat,dtype=object)\n",
    "def get_lens(tracks):\n",
    "    return pd.Series([len(trk) for trk in tracks]).value_counts()\n",
    "def get_feature_index(feature_type,features):\n",
    "    for idx,fet in enumerate(features):\n",
    "        if fet in feature_type:\n",
    "            return idx\n",
    "    return 0\n",
    "def cut_feture_vecs_and_preprocess(tracks,feature_type,ts_len,cut_longer_ts=False):\n",
    "    if cut_longer_ts:\n",
    "        track_cut = np.array([trk[:ts_len] for trk in tracks if len(trk)>=ts_len])\n",
    "    else:\n",
    "        tracks_cut = np.array([trk for trk in tracks if len(trk)==ts_len])\n",
    "    if 'centroids' in feature_type:\n",
    "        track_cut = centroids_zero_center(track_cut)\n",
    "    return track_cut\n",
    "def save(tracks_final,well_name):\n",
    "    np.save('../npy_files/'+well_name+'.npy',tracks_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_results_folder_PATH_to_arrays(features=['centroids','morphologies','embeddings'],ts_len=10,cut_longer_ts=False,save=False,name_ext=\"\"):\n",
    "    all_tracks = []\n",
    "    wells = []\n",
    "    all_paths = [path for path, subdir, files in os.walk(PATH)]\n",
    "    for path in all_paths:\n",
    "        feature_vecs_cut = []\n",
    "        all_files = [file for file in glob(os.path.join(path, EXT))]\n",
    "        if(len(all_files)<1):\n",
    "            continue\n",
    "        for file in all_files:\n",
    "            file_name = file.split('_')\n",
    "            well_name = file_name[2]\n",
    "            feature_type = file_name[-1]\n",
    "            if(not any(fet in feature_type for fet in features)):\n",
    "                continue\n",
    "            df_str = pd.read_csv(file,index_col=[0])\n",
    "            splitted = []\n",
    "            for cell_id, series in df_str.iterrows():\n",
    "                tracks = np.array(using_clump(np.array(series)),dtype=object)\n",
    "                for tr in tracks:\n",
    "                    splitted.append(tr)\n",
    "            tracks_str = np.array(splitted,dtype=object) \n",
    "            #print(\"tracks_str shape: \",tracks_str.shape)\n",
    "            tracks = str_array_to_float(tracks_str)\n",
    "            tracks_cut = cut_feture_vecs_and_preprocess(tracks,feature_type,ts_len,cut_longer_ts)\n",
    "            feature_vecs_cut.append(tracks_cut)\n",
    "        feature_vecs_cut = np.dstack(feature_vecs_cut)\n",
    "        if(len(feature_vecs_cut[0])>0):\n",
    "            print(feature_vecs_cut.shape)\n",
    "            all_tracks.append(feature_vecs_cut)\n",
    "            wells.append(well_name)\n",
    "    #return all_tracks,wells\n",
    "    labels = []\n",
    "    for well_name,tracks_vec in zip(wells,all_tracks):\n",
    "        labels.append(np.repeat(well_name,len(tracks_vec)))\n",
    "\n",
    "    results_tracks = np.vstack(all_tracks)\n",
    "    results_labels = np.concatenate(labels)\n",
    "    if(save):\n",
    "        np.save('../npy_files/features'+name_ext+'.npy',results_tracks)\n",
    "        np.save('../npy_files/labels'+name_ext+'.npy',results_labels)\n",
    "    return results_tracks,results_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = from_results_folder_PATH_to_arrays(features=['centroids','morphologies'],ts_len=12,cut_longer_ts=True,save=True,name_ext=\"_All12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests and single fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "def using_clump(a):\n",
    "    return [a[s] for s in np.ma.clump_unmasked(np.ma.masked_where(a.astype(str)==str(np.nan),a))]\n",
    "def normalize_centroids_in_tracks(tracks_arr):\n",
    "    for centroids_arr in tracks_arr:\n",
    "        centroids_arr-=centroids_arr[0]\n",
    "    return tracks_arr\n",
    "def str_array_to_float(arr_of_arr_of_str):\n",
    "    final_mat = []\n",
    "    for arr_of_arr in arr_of_arr_of_str:\n",
    "        float_ts = []\n",
    "        for str in arr_of_arr:\n",
    "            float_arr = [float(i) for i in re.findall(\"\\d+\\.\\d+\",str)]\n",
    "            if(len(float_arr)>=2):\n",
    "                float_ts.append(float_arr)\n",
    "        if(len(float_ts)>=1):\n",
    "            final_mat.append(float_ts)\n",
    "    return np.array(final_mat)\n",
    "def get_lens(tracks):\n",
    "    return pd.Series([len(trk) for trk in tracks]).value_counts()\n",
    "def cut_tracks_and_save(tracks,well_name,ts_len,cut_longer_ts=False,save=True):\n",
    "    if(cut_longer_ts):\n",
    "        tracks_final = np.array([trk[:ts_len] for trk in tracks if len(trk)>=ts_len])\n",
    "    else:\n",
    "        tracks_final = np.array([trk for trk in tracks if len(trk)==ts_len])\n",
    "    track_final_norm=normalize_centroids_in_tracks(tracks_final)\n",
    "    if(save):\n",
    "        np.save('../npy_files/'+well_name+'.npy',track_final_norm)\n",
    "    return track_final_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_path_to_npy(csv_path,well_name,ts_len,cut_longer_ts=False):\n",
    "    df_str = pd.read_csv(csv_path,index_col=[0])\n",
    "    splitted = []\n",
    "    id_well_index = []\n",
    "    for cell_id, series in df_str.iterrows():\n",
    "        tracks = np.array(using_clump(np.array(series)))\n",
    "        for tr in tracks:\n",
    "            splitted.append(tr)\n",
    "    tracks_str = np.array(splitted) \n",
    "    print(\"tracks_str shape: \",tracks_str.shape)\n",
    "    tracks = str_array_to_float(tracks_str)\n",
    "    cut_tracks_and_save(tracks,well_name,10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_results_folder_PATH_to_arrays():\n",
    "    all_tracks = []\n",
    "    wells = []\n",
    "    all_csv_files = [file\n",
    "                 for path, subdir, files in os.walk(PATH)\n",
    "                 for file in glob(os.path.join(path, EXT))]\n",
    "    for file in all_csv_files:\n",
    "        file_name = file.split('_')\n",
    "        well_name = file_name[1]\n",
    "        df_str = pd.read_csv(file,index_col=[0])\n",
    "        splitted = []\n",
    "        id_well_index = []\n",
    "        for cell_id, series in df_str.iterrows():\n",
    "            tracks = np.array(using_clump(np.array(series)))\n",
    "            for tr in tracks:\n",
    "                splitted.append(tr)\n",
    "        tracks_str = np.array(splitted) \n",
    "        print(\"tracks_str shape: \",tracks_str.shape)\n",
    "        tracks = str_array_to_float(tracks_str)\n",
    "        all_tracks.append(tracks)\n",
    "        wells.append(well_name)\n",
    "    return all_tracks,wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results'\n",
    "EXT = \"*centroids.csv\"\n",
    "all_tracks,wells = from_results_folder_PATH_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "labels = []\n",
    "for well_name,tracks in zip(wells,all_tracks):\n",
    "    tracks_norm_cut = cut_tracks_and_save(tracks,well_name,12,True)\n",
    "    all.append(tracks_norm_cut)\n",
    "    labels.append(np.repeat(well_name,len(tracks_norm_cut)))\n",
    "\n",
    "results_tracks = np.vstack(all)\n",
    "results_labels = np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../npy_files/tracks.npy',results_tracks)\n",
    "np.save('../npy_files/labels.npy',results_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results'\n",
    "EXT = \"*morphologies.csv\"\n",
    "all_tracks,wells = from_results_folder_PATH_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "labels = []\n",
    "for well_name,tracks in zip(wells,all_tracks):\n",
    "    tracks_norm_cut = cut_tracks_and_save(tracks,well_name,7,True)\n",
    "    all.append(tracks_norm_cut)\n",
    "    labels.append(np.repeat(well_name,len(tracks_norm_cut)))\n",
    "\n",
    "results_tracks = np.vstack(all)\n",
    "results_labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../npy_files/morph.npy',results_tracks) \n",
    "np.save('../npy_files/labels_morph.npy',results_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results_All'\n",
    "EXT = \"*.csv\"\n",
    "all_csv_files = [file\n",
    "                for path, subdir, files in os.walk(PATH)\n",
    "                for file in glob(os.path.join(path, EXT))]\n",
    "                \n",
    "all_paths = [path for path, subdir, files in os.walk(PATH)]\n",
    "lens = []\n",
    "for path in all_paths:\n",
    "    all_files = [file for file in glob(os.path.join(path, EXT)) ]\n",
    "    #print(all_files) \n",
    "    lens.append(len(all_files))\n",
    "    for file in all_files:\n",
    "        file_name = file.split('_')\n",
    "        well_name = file_name[2]\n",
    "        view_name = file_name[3]\n",
    "        crop_name = file_name[5]\n",
    "        print(f'well:{well_name} , view:{view_name}, crop:{crop_name}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lens).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_csv_files:\n",
    "    file_name = file.split('_')\n",
    "    print(file_name[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_csv_files:\n",
    "    file_name = file.split('_')\n",
    "    well_name = file_name[1]\n",
    "    view_name = file_name[2]\n",
    "    crop_name = file_name[4]\n",
    "    print(f'well:{well_name} , view:{view_name}, crop:{crop_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path to a centroids.csv\n",
    "comment out mac/windows file depending on os you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv('/Users/amosavni/university/DeepLearningWorkshop/deepcell_mod/DL-WORKSHOP/results/Results_D2_4_crop_0_start_2_2022-08-25_11-10-58/centroids.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strings df to array of array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "id_well_index = []\n",
    "for cell_id, series in df_t.iterrows():\n",
    "    tracks = np.array(using_clump(np.array(series)))\n",
    "    for tr in tracks:\n",
    "        splitted.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_str = np.array(splitted) \n",
    "print(tracks_str.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = str_array_to_float(tracks_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_lens(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_final = np.array([trk for trk in tracks if len(trk)==10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_final_norm=normalize_centroids_in_tracks(tracks_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('track_final_norm.npy',track_final_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl_work_mod': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c034c402205727166c9c9dd79643745cea02dc6588a665f44be427a01cecf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
