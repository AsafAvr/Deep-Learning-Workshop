{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoders - Effort to compress to latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29808, 16, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load('data_files/features_All16.npy')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_autoencoder(input_dim, timesteps, n_filters=50, kernel_size=10, strides=1, pool_size=10, n_units=[50, 1]):\n",
    "    \"\"\"\n",
    "    Temporal Autoencoder (TAE) model with Convolutional and BiLSTM layers.\n",
    "\n",
    "    # Arguments\n",
    "        input_dim: input dimension\n",
    "        timesteps: number of timesteps (can be None for variable length sequences)\n",
    "        n_filters: number of filters in convolutional layer\n",
    "        kernel_size: size of kernel in convolutional layer\n",
    "        strides: strides in convolutional layer\n",
    "        pool_size: pooling size in max pooling layer, must divide time series length\n",
    "        n_units: numbers of units in the two BiLSTM layers\n",
    "        alpha: coefficient in Student's kernel\n",
    "        dist_metric: distance metric between latent sequences\n",
    "\n",
    "    # Return\n",
    "        (ae_model, encoder_model, decoder_model): AE, encoder and decoder models\n",
    "    \"\"\"\n",
    "    assert(timesteps % pool_size == 0)\n",
    "\n",
    "    # Input\n",
    "    x = Input(shape=(timesteps, input_dim), name='input_seq')\n",
    "\n",
    "    # Encoder\n",
    "    encoded = Conv1D(n_filters, kernel_size, strides=strides, padding='same', activation='linear')(x)\n",
    "    encoded = LeakyReLU()(encoded)\n",
    "    encoded = MaxPool1D(pool_size)(encoded)\n",
    "    encoded = Bidirectional(CuDNNLSTM(n_units[0], return_sequences=True), merge_mode='sum')(encoded)\n",
    "    encoded = LeakyReLU()(encoded)\n",
    "    encoded = Bidirectional(CuDNNLSTM(n_units[1], return_sequences=True), merge_mode='sum')(encoded)\n",
    "    encoded = LeakyReLU(name='latent')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Reshape((-1, 1, n_units[1]), name='reshape')(encoded)\n",
    "    decoded = UpSampling2D((pool_size, 1), name='upsampling')(decoded)  #decoded = UpSampling1D(pool_size, name='upsampling')(decoded)\n",
    "    decoded = Conv2DTranspose(input_dim, (kernel_size, 1), padding='same', name='conv2dtranspose')(decoded)\n",
    "    output = Reshape((-1, input_dim), name='output_seq')(decoded)  #output = Conv1D(1, kernel_size, strides=strides, padding='same', activation='linear', name='output_seq')(decoded)\n",
    "\n",
    "    # AE model\n",
    "    autoencoder = Model(inputs=x, outputs=output, name='AE')\n",
    "\n",
    "    # Encoder model\n",
    "    encoder = Model(inputs=x, outputs=encoded, name='encoder')\n",
    "\n",
    "    # Create input for decoder model\n",
    "    encoded_input = Input(shape=(timesteps // pool_size, n_units[1]), name='decoder_input')\n",
    "\n",
    "    # Internal layers in decoder\n",
    "    decoded = autoencoder.get_layer('reshape')(encoded_input)\n",
    "    decoded = autoencoder.get_layer('upsampling')(decoded)\n",
    "    decoded = autoencoder.get_layer('conv2dtranspose')(decoded)\n",
    "    decoder_output = autoencoder.get_layer('output_seq')(decoded)\n",
    "\n",
    "    # Decoder model\n",
    "    decoder = Model(inputs=encoded_input, outputs=decoder_output, name='decoder')\n",
    "\n",
    "    return autoencoder, encoder, decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl_work_mod': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c034c402205727166c9c9dd79643745cea02dc6588a665f44be427a01cecf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
