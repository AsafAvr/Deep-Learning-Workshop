{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from random import randint\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import plotting_funcs as pf\n",
    "import clustering_model as cm\n",
    "import config as conf\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3864, 32, 5) (3864,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('x_clean.npy')\n",
    "y = np.load('y_clean.npy')\n",
    "types = np.array([conf.wells_to_genetype_dict[well] for well in y])\n",
    "y_letter = np.array([well[:1] for well in y])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labs = le.fit_transform(y)\n",
    "labs_by_letter = le.fit_transform(y_letter)\n",
    "labs_by_type = le.fit_transform(types)\n",
    "X, labs\n",
    "print(X.shape , labs_by_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(types).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,labs_by_type,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3091, 32, 5) (3091,)\n",
      "(773, 32, 5) (773,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "input_dim = X_train.shape[-1]\n",
    "num_labels = len(np.unique(y_train))\n",
    "timesteps = X_train.shape[-2]\n",
    "n_filters = [64,64,32]\n",
    "kernel_size = 8\n",
    "strides = 1\n",
    "pool_size = 8\n",
    "n_units = [64,8]\n",
    "\n",
    "optimizer='adam'\n",
    "#optimizer = Adam(lr=0.01)\n",
    "#loss = 'categorical_crossentropy' # need one ot encoded labels\n",
    "loss = 'sparse_categorical_crossentropy' # need label encoded labels\n",
    "epochs=100\n",
    "batch_size=256\n",
    "save_dir='results/tmp'\n",
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_seq (InputLayer)      [(None, 32, 5)]           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 32, 64)            2624      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 32, 64)            32832     \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 32, 32)            16416     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 4, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 4, 64)            49664     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 4, 64)             0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 4, 8)             4672      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " latent (Flatten)            (None, 32)                0         \n",
      "                                                                 \n",
      " classes (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,373\n",
      "Trainable params: 106,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model,encoder_model = cm.temporal_classifier(input_dim,num_labels,timesteps,n_filters,kernel_size,strides,pool_size,n_units)\n",
    "classifier_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 7s 144ms/step - loss: 1.3206 - accuracy: 0.5403 - val_loss: 1.2369 - val_accuracy: 0.5317\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.2294 - accuracy: 0.5458 - val_loss: 1.2378 - val_accuracy: 0.5317\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2204 - accuracy: 0.5458 - val_loss: 1.2338 - val_accuracy: 0.5317\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2143 - accuracy: 0.5458 - val_loss: 1.2377 - val_accuracy: 0.5317\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.2107 - accuracy: 0.5458 - val_loss: 1.2341 - val_accuracy: 0.5317\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1.2072 - accuracy: 0.5458 - val_loss: 1.2390 - val_accuracy: 0.5317\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.2031 - accuracy: 0.5458 - val_loss: 1.2375 - val_accuracy: 0.5317\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2003 - accuracy: 0.5458 - val_loss: 1.2392 - val_accuracy: 0.5317\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.1969 - accuracy: 0.5458 - val_loss: 1.2380 - val_accuracy: 0.5317\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 1.1898 - accuracy: 0.5464 - val_loss: 1.2457 - val_accuracy: 0.5330\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1822 - accuracy: 0.5464 - val_loss: 1.2403 - val_accuracy: 0.5330\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.1734 - accuracy: 0.5464 - val_loss: 1.2479 - val_accuracy: 0.5330\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.1666 - accuracy: 0.5467 - val_loss: 1.2501 - val_accuracy: 0.5356\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1558 - accuracy: 0.5477 - val_loss: 1.2623 - val_accuracy: 0.5330\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 1.1661 - accuracy: 0.5480 - val_loss: 1.2495 - val_accuracy: 0.5343\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1.1539 - accuracy: 0.5471 - val_loss: 1.2542 - val_accuracy: 0.5343\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 1.1450 - accuracy: 0.5500 - val_loss: 1.2637 - val_accuracy: 0.5356\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 1.1224 - accuracy: 0.5552 - val_loss: 1.2615 - val_accuracy: 0.5356\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 1.1137 - accuracy: 0.5597 - val_loss: 1.2739 - val_accuracy: 0.5226\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.1036 - accuracy: 0.5620 - val_loss: 1.2729 - val_accuracy: 0.5343\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.0914 - accuracy: 0.5665 - val_loss: 1.2831 - val_accuracy: 0.5291\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.0766 - accuracy: 0.5726 - val_loss: 1.2935 - val_accuracy: 0.5317\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 1.0562 - accuracy: 0.5707 - val_loss: 1.3281 - val_accuracy: 0.5188\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1.0477 - accuracy: 0.5768 - val_loss: 1.3253 - val_accuracy: 0.4890\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.0083 - accuracy: 0.5940 - val_loss: 1.3327 - val_accuracy: 0.4851\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.9908 - accuracy: 0.6066 - val_loss: 1.3500 - val_accuracy: 0.4994\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.9726 - accuracy: 0.6166 - val_loss: 1.3603 - val_accuracy: 0.5019\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.9722 - accuracy: 0.6179 - val_loss: 1.3822 - val_accuracy: 0.4580\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 0.9375 - accuracy: 0.6296 - val_loss: 1.3979 - val_accuracy: 0.4386\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 0.9188 - accuracy: 0.6386 - val_loss: 1.4133 - val_accuracy: 0.4812\n",
      "Pretraining time:  21.18906807899475\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "history = classifier_model.fit(X_train, y_train,validation_data=(X_test,y_test) , batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "print('Pretraining time: ', time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_acc = classifier_model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = classifier_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
