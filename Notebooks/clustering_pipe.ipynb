{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "PATH = '../Results'\n",
    "EXT = \"*centroids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "def using_clump(a):\n",
    "    return [a[s] for s in np.ma.clump_unmasked(np.ma.masked_where(a.astype(str)==str(np.nan),a))]\n",
    "def normalize_centroids_in_tracks(tracks_arr):\n",
    "    for centroids_arr in tracks_arr:\n",
    "        centroids_arr-=centroids_arr[0]\n",
    "    return tracks_arr\n",
    "def str_array_to_float(arr_of_arr_of_str):\n",
    "    final_mat = []\n",
    "    for arr_of_arr in arr_of_arr_of_str:\n",
    "        float_ts = []\n",
    "        for str in arr_of_arr:\n",
    "            float_arr = [float(i) for i in re.findall(\"\\d+\\.\\d+\",str)]\n",
    "            if(len(float_arr)>=2):\n",
    "                float_ts.append(float_arr)\n",
    "        if(len(float_ts)>=1):\n",
    "            final_mat.append(float_ts)\n",
    "    return np.array(final_mat)\n",
    "def get_lens(tracks):\n",
    "    return pd.Series([len(trk) for trk in tracks]).value_counts()\n",
    "def cut_tracks_and_save(tracks,well_name,ts_len,cut_longer_ts=False,save=True):\n",
    "    if(cut_longer_ts):\n",
    "        tracks_final = np.array([trk[:ts_len] for trk in tracks if len(trk)>=ts_len])\n",
    "    else:\n",
    "        tracks_final = np.array([trk for trk in tracks if len(trk)==ts_len])\n",
    "    track_final_norm=normalize_centroids_in_tracks(tracks_final)\n",
    "    if(save):\n",
    "        np.save('../npy_files/'+well_name+'.npy',track_final_norm)\n",
    "    return track_final_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_path_to_npy(csv_path,well_name,ts_len,cut_longer_ts=False):\n",
    "    df_str = pd.read_csv(csv_path,index_col=[0])\n",
    "    splitted = []\n",
    "    id_well_index = []\n",
    "    for cell_id, series in df_str.iterrows():\n",
    "        tracks = np.array(using_clump(np.array(series)))\n",
    "        for tr in tracks:\n",
    "            splitted.append(tr)\n",
    "    tracks_str = np.array(splitted) \n",
    "    print(\"tracks_str shape: \",tracks_str.shape)\n",
    "    tracks = str_array_to_float(tracks_str)\n",
    "    cut_tracks_and_save(tracks,well_name,10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_results_folder_PATH_to_arrays():\n",
    "    all_tracks = []\n",
    "    wells = []\n",
    "    all_csv_files = [file\n",
    "                 for path, subdir, files in os.walk(PATH)\n",
    "                 for file in glob(os.path.join(path, EXT))]\n",
    "    for file in all_csv_files:\n",
    "        file_name = file.split('_')\n",
    "        well_name = file_name[1]\n",
    "        df_str = pd.read_csv(file,index_col=[0])\n",
    "        splitted = []\n",
    "        id_well_index = []\n",
    "        for cell_id, series in df_str.iterrows():\n",
    "            tracks = np.array(using_clump(np.array(series)))\n",
    "            for tr in tracks:\n",
    "                splitted.append(tr)\n",
    "        tracks_str = np.array(splitted) \n",
    "        print(\"tracks_str shape: \",tracks_str.shape)\n",
    "        tracks = str_array_to_float(tracks_str)\n",
    "        all_tracks.append(tracks)\n",
    "        wells.append(well_name)\n",
    "    return all_tracks,wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks,wells = from_results_folder_PATH_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "labels = []\n",
    "for well_name,tracks in zip(wells,all_tracks):\n",
    "    tracks_norm_cut = cut_tracks_and_save(tracks,well_name,12,True)\n",
    "    all.append(tracks_norm_cut)\n",
    "    labels.append(np.repeat(well_name,len(tracks_norm_cut)))\n",
    "\n",
    "results_tracks = np.vstack(all)\n",
    "results_labels = np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../npy_files/tracks.npy',results_tracks)\n",
    "np.save('../npy_files/labels.npy',results_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = [file\n",
    "                 for path, subdir, files in os.walk(PATH)\n",
    "                 for file in glob(os.path.join(path, EXT))]\n",
    "print(all_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_csv_files:\n",
    "    file_name = file.split('_')\n",
    "    well_name = file_name[1]\n",
    "    view_name = file_name[2]\n",
    "    crop_name = file_name[4]\n",
    "    print(f'well:{well_name} , view:{view_name}, crop:{crop_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_str shape:  (1502,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/1242426391.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tracks = np.array(using_clump(np.array(series)))\n",
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/1242426391.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tracks_str = np.array(splitted)\n",
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/1443410114.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_mat)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/amosavni/university/DeepLearningWorkshop/deepcell_mod/DL-WORKSHOP/results/Results_D2_4_crop_0_start_2_2022-08-25_11-10-58/centroids.csv'\n",
    "from_csv_path_to_npy(path,'D2_4_crop_0',10,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path to a centroids.csv\n",
    "comment out mac/windows file depending on os you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv('/Users/amosavni/university/DeepLearningWorkshop/deepcell_mod/DL-WORKSHOP/results/Results_D2_4_crop_0_start_2_2022-08-25_11-10-58/centroids.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strings df to array of array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/2767955733.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tracks = np.array(using_clump(np.array(series)))\n"
     ]
    }
   ],
   "source": [
    "splitted = []\n",
    "id_well_index = []\n",
    "for cell_id, series in df_t.iterrows():\n",
    "    tracks = np.array(using_clump(np.array(series)))\n",
    "    for tr in tracks:\n",
    "        splitted.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/339763255.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tracks_str = np.array(splitted)\n"
     ]
    }
   ],
   "source": [
    "tracks_str = np.array(splitted) \n",
    "print(tracks_str.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/khx_n6gj1fgfgkzsbv62f8sw0000gn/T/ipykernel_4293/1399472887.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_mat)\n"
     ]
    }
   ],
   "source": [
    "tracks = str_array_to_float(tracks_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     429\n",
      "2     215\n",
      "4     137\n",
      "3     134\n",
      "5      95\n",
      "11     64\n",
      "6      56\n",
      "7      55\n",
      "10     51\n",
      "8      42\n",
      "9      42\n",
      "12     37\n",
      "15     18\n",
      "13     18\n",
      "14     18\n",
      "16     14\n",
      "17      9\n",
      "20      9\n",
      "24      7\n",
      "21      7\n",
      "19      6\n",
      "26      5\n",
      "29      4\n",
      "23      3\n",
      "28      3\n",
      "22      3\n",
      "27      3\n",
      "18      2\n",
      "30      1\n",
      "25      1\n",
      "37      1\n",
      "33      1\n",
      "40      1\n",
      "36      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_lens(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_final = np.array([trk for trk in tracks if len(trk)==10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_final_norm=normalize_centroids_in_tracks(tracks_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('track_final_norm.npy',track_final_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a184a0d3ed5e1b4c939c8efe33eb084c0e496ed31866d3571697232af7bf5674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
