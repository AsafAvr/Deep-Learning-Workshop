{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "PATH = '../Results_All'\n",
    "EXT = \"*.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final pipeline for all features in all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "def using_clump(a):\n",
    "    return [a[s] for s in np.ma.clump_unmasked(np.ma.masked_where(a.astype(str)==str(np.nan),a))]\n",
    "def centroids_zero_center(tracks_arr):\n",
    "    for centroids_arr in tracks_arr:\n",
    "        centroids_arr-=centroids_arr[0]\n",
    "    return tracks_arr\n",
    "numeric_const_pattern = '[-+]? (?: (?: \\d* \\. \\d+ ) | (?: \\d+ \\.? ) )(?: [Ee] [+-]? \\d+ ) ?'\n",
    "rx = re.compile(numeric_const_pattern, re.VERBOSE)\n",
    "def str_array_to_float(arr_of_arr_of_str):\n",
    "    final_mat = []\n",
    "    for arr_of_arr in arr_of_arr_of_str:\n",
    "        float_ts = []\n",
    "        for str in arr_of_arr:\n",
    "            float_arr = [float(i) for i in rx.findall(str)]\n",
    "            if(len(float_arr)>=2):\n",
    "                float_ts.append(float_arr)\n",
    "        if(len(float_ts)>=1):\n",
    "            final_mat.append(float_ts)\n",
    "    return np.array(final_mat,dtype=object)\n",
    "def get_lens(tracks):\n",
    "    return pd.Series([len(trk) for trk in tracks]).value_counts()\n",
    "def get_feature_index(feature_type,features):\n",
    "    for idx,fet in enumerate(features):\n",
    "        if fet in feature_type:\n",
    "            return idx\n",
    "    return 0\n",
    "def cut_feture_vecs_and_preprocess(tracks,feature_type,ts_len,cut_longer_ts=False):\n",
    "    if(cut_longer_ts):\n",
    "        track_cut = np.array([trk[:ts_len] for trk in tracks if len(trk)>=ts_len])\n",
    "    else:\n",
    "        tracks_cut = np.array([trk for trk in tracks if len(trk)==ts_len])\n",
    "    if 'centroids' in feature_type:\n",
    "        track_cut = centroids_zero_center(track_cut)\n",
    "    return track_cut\n",
    "def save(tracks_final,well_name):\n",
    "    np.save('../npy_files/'+well_name+'.npy',tracks_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_results_folder_PATH_to_arrays(features=['centroids','morphologies','embeddings'],ts_len=10,cut_longer_ts=False,save=False,name_ext=\"\"):\n",
    "    all_tracks = []\n",
    "    wells = []\n",
    "    all_paths = [path for path, subdir, files in os.walk(PATH)]\n",
    "    for path in all_paths:\n",
    "        feature_vecs_cut = []\n",
    "        all_files = [file for file in glob(os.path.join(path, EXT))]\n",
    "        if(len(all_files)<1):\n",
    "            continue\n",
    "        for file in all_files:\n",
    "            file_name = file.split('_')\n",
    "            well_name = file_name[1]\n",
    "            feature_type = file_name[-1]\n",
    "            if(not any(fet in feature_type for fet in features)):\n",
    "                continue\n",
    "            df_str = pd.read_csv(file,index_col=[0])\n",
    "            splitted = []\n",
    "            for cell_id, series in df_str.iterrows():\n",
    "                tracks = np.array(using_clump(np.array(series)),dtype=object)\n",
    "                for tr in tracks:\n",
    "                    splitted.append(tr)\n",
    "            tracks_str = np.array(splitted,dtype=object) \n",
    "            #print(\"tracks_str shape: \",tracks_str.shape)\n",
    "            tracks = str_array_to_float(tracks_str)\n",
    "            tracks_cut = cut_feture_vecs_and_preprocess(tracks,feature_type,ts_len,cut_longer_ts)\n",
    "            feature_vecs_cut.append(tracks_cut)\n",
    "        feature_vecs_cut = np.dstack(feature_vecs_cut)\n",
    "        if(len(feature_vecs_cut[0])>0):\n",
    "            print(feature_vecs_cut.shape)\n",
    "            all_tracks.append(feature_vecs_cut)\n",
    "            wells.append(well_name)\n",
    "    #return all_tracks,wells\n",
    "    labels = []\n",
    "    for well_name,tracks_vec in zip(wells,all_tracks):\n",
    "        labels.append(np.repeat(well_name,len(tracks_vec)))\n",
    "\n",
    "    results_tracks = np.vstack(all_tracks)\n",
    "    results_labels = np.concatenate(labels)\n",
    "    if(save):\n",
    "        np.save('../npy_files/features'+name_ext+'.npy',results_tracks)\n",
    "        np.save('../npy_files/labels'+name_ext+'.npy',results_labels)\n",
    "    return results_tracks,results_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 12, 5)\n",
      "(47, 12, 5)\n",
      "(31, 12, 5)\n",
      "(43, 12, 5)\n",
      "(16, 12, 5)\n",
      "(67, 12, 5)\n",
      "(21, 12, 5)\n",
      "(34, 12, 5)\n",
      "(50, 12, 5)\n",
      "(93, 12, 5)\n",
      "(161, 12, 5)\n",
      "(47, 12, 5)\n",
      "(211, 12, 5)\n",
      "(44, 12, 5)\n",
      "(51, 12, 5)\n",
      "(22, 12, 5)\n",
      "(206, 12, 5)\n",
      "(22, 12, 5)\n",
      "(103, 12, 5)\n",
      "(162, 12, 5)\n",
      "(16, 12, 5)\n",
      "(91, 12, 5)\n",
      "(14, 12, 5)\n",
      "(99, 12, 5)\n",
      "(44, 12, 5)\n",
      "(180, 12, 5)\n",
      "(31, 12, 5)\n",
      "(113, 12, 5)\n",
      "(20, 12, 5)\n",
      "(135, 12, 5)\n",
      "(27, 12, 5)\n",
      "(61, 12, 5)\n",
      "(295, 12, 5)\n",
      "(63, 12, 5)\n",
      "(2, 12, 5)\n",
      "(107, 12, 5)\n",
      "(21, 12, 5)\n",
      "(53, 12, 5)\n",
      "(93, 12, 5)\n",
      "(17, 12, 5)\n",
      "(293, 12, 5)\n",
      "(55, 12, 5)\n",
      "(5, 12, 5)\n",
      "(25, 12, 5)\n",
      "(29, 12, 5)\n",
      "(10, 12, 5)\n",
      "(26, 12, 5)\n",
      "(38, 12, 5)\n",
      "(78, 12, 5)\n",
      "(9, 12, 5)\n",
      "(79, 12, 5)\n",
      "(183, 12, 5)\n",
      "(34, 12, 5)\n",
      "(39, 12, 5)\n",
      "(94, 12, 5)\n",
      "(14, 12, 5)\n",
      "(186, 12, 5)\n",
      "(9, 12, 5)\n",
      "(52, 12, 5)\n",
      "(105, 12, 5)\n",
      "(69, 12, 5)\n",
      "(43, 12, 5)\n",
      "(58, 12, 5)\n",
      "(68, 12, 5)\n",
      "(33, 12, 5)\n",
      "(80, 12, 5)\n",
      "(58, 12, 5)\n",
      "(5, 12, 5)\n",
      "(115, 12, 5)\n",
      "(17, 12, 5)\n",
      "(48, 12, 5)\n",
      "(178, 12, 5)\n",
      "(12, 12, 5)\n",
      "(20, 12, 5)\n",
      "(56, 12, 5)\n",
      "(6, 12, 5)\n",
      "(15, 12, 5)\n",
      "(56, 12, 5)\n",
      "(4, 12, 5)\n",
      "(4, 12, 5)\n",
      "(18, 12, 5)\n",
      "(37, 12, 5)\n",
      "(75, 12, 5)\n",
      "(192, 12, 5)\n",
      "(177, 12, 5)\n",
      "(178, 12, 5)\n",
      "(39, 12, 5)\n",
      "(111, 12, 5)\n",
      "(104, 12, 5)\n",
      "(20, 12, 5)\n",
      "(251, 12, 5)\n",
      "(6, 12, 5)\n",
      "(261, 12, 5)\n",
      "(73, 12, 5)\n",
      "(44, 12, 5)\n",
      "(15, 12, 5)\n",
      "(70, 12, 5)\n",
      "(87, 12, 5)\n",
      "(17, 12, 5)\n",
      "(36, 12, 5)\n",
      "(59, 12, 5)\n",
      "(28, 12, 5)\n",
      "(151, 12, 5)\n",
      "(59, 12, 5)\n",
      "(60, 12, 5)\n",
      "(25, 12, 5)\n",
      "(39, 12, 5)\n",
      "(293, 12, 5)\n",
      "(87, 12, 5)\n",
      "(21, 12, 5)\n",
      "(57, 12, 5)\n",
      "(10, 12, 5)\n",
      "(298, 12, 5)\n",
      "(54, 12, 5)\n",
      "(79, 12, 5)\n",
      "(88, 12, 5)\n",
      "(24, 12, 5)\n",
      "(515, 12, 5)\n",
      "(9, 12, 5)\n",
      "(112, 12, 5)\n",
      "(1, 12, 5)\n",
      "(44, 12, 5)\n",
      "(105, 12, 5)\n",
      "(190, 12, 5)\n",
      "(32, 12, 5)\n",
      "(52, 12, 5)\n",
      "(108, 12, 5)\n",
      "(218, 12, 5)\n",
      "(123, 12, 5)\n",
      "(109, 12, 5)\n",
      "(82, 12, 5)\n",
      "(26, 12, 5)\n",
      "(30, 12, 5)\n",
      "(45, 12, 5)\n",
      "(31, 12, 5)\n",
      "(30, 12, 5)\n",
      "(115, 12, 5)\n",
      "(2, 12, 5)\n",
      "(106, 12, 5)\n",
      "(122, 12, 5)\n",
      "(5, 12, 5)\n",
      "(48, 12, 5)\n",
      "(83, 12, 5)\n",
      "(61, 12, 5)\n",
      "(77, 12, 5)\n",
      "(210, 12, 5)\n",
      "(34, 12, 5)\n",
      "(4, 12, 5)\n",
      "(136, 12, 5)\n",
      "(106, 12, 5)\n",
      "(124, 12, 5)\n",
      "(25, 12, 5)\n",
      "(18, 12, 5)\n",
      "(32, 12, 5)\n",
      "(149, 12, 5)\n",
      "(38, 12, 5)\n",
      "(263, 12, 5)\n",
      "(5, 12, 5)\n",
      "(17, 12, 5)\n",
      "(48, 12, 5)\n",
      "(68, 12, 5)\n",
      "(21, 12, 5)\n",
      "(5, 12, 5)\n",
      "(13, 12, 5)\n",
      "(118, 12, 5)\n",
      "(121, 12, 5)\n",
      "(7, 12, 5)\n",
      "(65, 12, 5)\n",
      "(7, 12, 5)\n",
      "(5, 12, 5)\n",
      "(26, 12, 5)\n",
      "(29, 12, 5)\n",
      "(78, 12, 5)\n",
      "(7, 12, 5)\n",
      "(231, 12, 5)\n",
      "(109, 12, 5)\n",
      "(37, 12, 5)\n",
      "(23, 12, 5)\n",
      "(43, 12, 5)\n",
      "(130, 12, 5)\n",
      "(73, 12, 5)\n",
      "(20, 12, 5)\n",
      "(151, 12, 5)\n",
      "(87, 12, 5)\n",
      "(85, 12, 5)\n",
      "(50, 12, 5)\n",
      "(9, 12, 5)\n",
      "(54, 12, 5)\n",
      "(83, 12, 5)\n",
      "(56, 12, 5)\n",
      "(27, 12, 5)\n",
      "(26, 12, 5)\n",
      "(61, 12, 5)\n",
      "(110, 12, 5)\n",
      "(94, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "x,y = from_results_folder_PATH_to_arrays(features=['centroids','morphologies'],ts_len=12,cut_longer_ts=True,save=True,name_ext=\"_All12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14330, 12, 5)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests and single fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "def using_clump(a):\n",
    "    return [a[s] for s in np.ma.clump_unmasked(np.ma.masked_where(a.astype(str)==str(np.nan),a))]\n",
    "def normalize_centroids_in_tracks(tracks_arr):\n",
    "    for centroids_arr in tracks_arr:\n",
    "        centroids_arr-=centroids_arr[0]\n",
    "    return tracks_arr\n",
    "def str_array_to_float(arr_of_arr_of_str):\n",
    "    final_mat = []\n",
    "    for arr_of_arr in arr_of_arr_of_str:\n",
    "        float_ts = []\n",
    "        for str in arr_of_arr:\n",
    "            float_arr = [float(i) for i in re.findall(\"\\d+\\.\\d+\",str)]\n",
    "            if(len(float_arr)>=2):\n",
    "                float_ts.append(float_arr)\n",
    "        if(len(float_ts)>=1):\n",
    "            final_mat.append(float_ts)\n",
    "    return np.array(final_mat)\n",
    "def get_lens(tracks):\n",
    "    return pd.Series([len(trk) for trk in tracks]).value_counts()\n",
    "def cut_tracks_and_save(tracks,well_name,ts_len,cut_longer_ts=False,save=True):\n",
    "    if(cut_longer_ts):\n",
    "        tracks_final = np.array([trk[:ts_len] for trk in tracks if len(trk)>=ts_len])\n",
    "    else:\n",
    "        tracks_final = np.array([trk for trk in tracks if len(trk)==ts_len])\n",
    "    track_final_norm=normalize_centroids_in_tracks(tracks_final)\n",
    "    if(save):\n",
    "        np.save('../npy_files/'+well_name+'.npy',track_final_norm)\n",
    "    return track_final_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_path_to_npy(csv_path,well_name,ts_len,cut_longer_ts=False):\n",
    "    df_str = pd.read_csv(csv_path,index_col=[0])\n",
    "    splitted = []\n",
    "    id_well_index = []\n",
    "    for cell_id, series in df_str.iterrows():\n",
    "        tracks = np.array(using_clump(np.array(series)))\n",
    "        for tr in tracks:\n",
    "            splitted.append(tr)\n",
    "    tracks_str = np.array(splitted) \n",
    "    print(\"tracks_str shape: \",tracks_str.shape)\n",
    "    tracks = str_array_to_float(tracks_str)\n",
    "    cut_tracks_and_save(tracks,well_name,10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_results_folder_PATH_to_arrays():\n",
    "    all_tracks = []\n",
    "    wells = []\n",
    "    all_csv_files = [file\n",
    "                 for path, subdir, files in os.walk(PATH)\n",
    "                 for file in glob(os.path.join(path, EXT))]\n",
    "    for file in all_csv_files:\n",
    "        file_name = file.split('_')\n",
    "        well_name = file_name[1]\n",
    "        df_str = pd.read_csv(file,index_col=[0])\n",
    "        splitted = []\n",
    "        id_well_index = []\n",
    "        for cell_id, series in df_str.iterrows():\n",
    "            tracks = np.array(using_clump(np.array(series)))\n",
    "            for tr in tracks:\n",
    "                splitted.append(tr)\n",
    "        tracks_str = np.array(splitted) \n",
    "        print(\"tracks_str shape: \",tracks_str.shape)\n",
    "        tracks = str_array_to_float(tracks_str)\n",
    "        all_tracks.append(tracks)\n",
    "        wells.append(well_name)\n",
    "    return all_tracks,wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results'\n",
    "EXT = \"*centroids.csv\"\n",
    "all_tracks,wells = from_results_folder_PATH_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "labels = []\n",
    "for well_name,tracks in zip(wells,all_tracks):\n",
    "    tracks_norm_cut = cut_tracks_and_save(tracks,well_name,12,True)\n",
    "    all.append(tracks_norm_cut)\n",
    "    labels.append(np.repeat(well_name,len(tracks_norm_cut)))\n",
    "\n",
    "results_tracks = np.vstack(all)\n",
    "results_labels = np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../npy_files/tracks.npy',results_tracks)\n",
    "np.save('../npy_files/labels.npy',results_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results'\n",
    "EXT = \"*morphologies.csv\"\n",
    "all_tracks,wells = from_results_folder_PATH_to_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "labels = []\n",
    "for well_name,tracks in zip(wells,all_tracks):\n",
    "    tracks_norm_cut = cut_tracks_and_save(tracks,well_name,7,True)\n",
    "    all.append(tracks_norm_cut)\n",
    "    labels.append(np.repeat(well_name,len(tracks_norm_cut)))\n",
    "\n",
    "results_tracks = np.vstack(all)\n",
    "results_labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8931"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../npy_files/morph.npy',results_tracks) \n",
    "np.save('../npy_files/labels_morph.npy',results_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Results_All'\n",
    "EXT = \"*.csv\"\n",
    "all_csv_files = [file\n",
    "                for path, subdir, files in os.walk(PATH)\n",
    "                for file in glob(os.path.join(path, EXT))]\n",
    "                \n",
    "all_paths = [path for path, subdir, files in os.walk(PATH)]\n",
    "lens = []\n",
    "for path in all_paths:\n",
    "    all_files = [file for file in glob(os.path.join(path, EXT)) ]\n",
    "    print(all_files) \n",
    "    lens.append(len(all_files))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    202\n",
       "0      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lens).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_csv_files:\n",
    "    file_name = file.split('_')\n",
    "    print(file_name[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_csv_files:\n",
    "    file_name = file.split('_')\n",
    "    well_name = file_name[1]\n",
    "    view_name = file_name[2]\n",
    "    crop_name = file_name[4]\n",
    "    print(f'well:{well_name} , view:{view_name}, crop:{crop_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path to a centroids.csv\n",
    "comment out mac/windows file depending on os you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv('/Users/amosavni/university/DeepLearningWorkshop/deepcell_mod/DL-WORKSHOP/results/Results_D2_4_crop_0_start_2_2022-08-25_11-10-58/centroids.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strings df to array of array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "id_well_index = []\n",
    "for cell_id, series in df_t.iterrows():\n",
    "    tracks = np.array(using_clump(np.array(series)))\n",
    "    for tr in tracks:\n",
    "        splitted.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_str = np.array(splitted) \n",
    "print(tracks_str.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = str_array_to_float(tracks_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_lens(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_final = np.array([trk for trk in tracks if len(trk)==10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_final_norm=normalize_centroids_in_tracks(tracks_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('track_final_norm.npy',track_final_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a184a0d3ed5e1b4c939c8efe33eb084c0e496ed31866d3571697232af7bf5674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
